{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1402a373",
   "metadata": {},
   "source": [
    "<h1 style=\"color: #191970;\" ><center>Machine Learning On The Wisconsin Breast Cancer Dataset</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e38e29",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#4169E1;\"> The Dataset Overview </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c125fbd7",
   "metadata": {},
   "source": [
    "The Wisconsin breast cancer dataset is the dataset that we have to investigate for this project. There are two variants of this dataset, the original one or the diagnostic one, I chose to use the original one. The dataset provides us with information on breast cancer tumors, it contains measurements recorded for 10 different features that tumors portray. The aim of the dataset is to classify what type of tumor a set of featues describe. The tumors have 2 possible labels, benign or malignant. Benign tumors are less serious than malignant, they tend to stay in place rather than spread out. They grow slowly overtime and often can be safely removed. Malignant are more serious cancerous tumors that can spread out to other parts in your body making them more difficult to treat.[1][11][12]\n",
    "\n",
    "The features measured in this dataset are charactaristics of the cell nuclei present in the tumor. The measurement are taken from inserting a needle tip into the breast mass and taking a digital image. The dataset has 10 attributes and 1 classifier.[1]\n",
    "<h5><center>The Dataset</center></h5>\n",
    "\n",
    "1. <b>Sample Code Number</b>(int) - Id number\n",
    "2. <b>Clump Thickness</b>(int) - 1-10\n",
    "3. <b>Uniformity Of Cell Size</b>(int) - 1-10\n",
    "4. <b>Uniformity Of Cell Shape</b>(int) - 1-10\n",
    "5. <b>Marginal Adhesion</b>(int) - 1-10\n",
    "6. <b>Single Epithelial Cell Size</b>(int) - 1-10\n",
    "7. <b>Bare Nuclei</b>(int) - 1-10\n",
    "8. <b>Bland Chromatin</b>(int) - 1-10\n",
    "9. <b>Normal Nucleoli</b>(int) - 1-10\n",
    "10. <b>Mitoses</b>(int) - 1-10\n",
    "11. <b>Class</b>(int) - (2 = Benign , 4= Malignant)\n",
    "\n",
    "I found my dataset on a website called [UCI](https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)). It can also be found on [Kaggle](https://www.kaggle.com/datasets/ninjacoding/breast-cancer-wisconsin-benign-or-malignant).[11][12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcabc1b",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#4169E1;\"> Lit Review On Machine Learning Classifiers </h2> \n",
    "\n",
    "The research paper I studied to provide analysis for this section of the project was called \"Diagnosis of Breast Cancer Pathology on the Wisconsin Dataset with the Help of Data Mining Classification and Clustering Techniques\". This research paper looks at five types of machine learning classifiers and how well they perform on the Wisconsin breast cancer dataset.These classification algorithms are all supervised learning algorithms because they take in lablled data to learn and decipher how these inputs are distinguished from one another so that it can then estimate new input data. Below I have given an overall review on the 5 different classifiers they used.[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584a81fe",
   "metadata": {},
   "source": [
    "<h3> Decision Tree Classifier (J48)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c4e8df",
   "metadata": {},
   "source": [
    "The first classification algorithm we will look at that was applied to the Wisconsin breast cancer dataset is the J48 algorithm which is also called the decision tree classifier. This practical algorithm divides features into groups by generating decision trees from datasets. It is easy and fast to use and the resulting output is comprehensible. \n",
    "\n",
    "This algorithm uses two concepts to create a decision tree, entropy and information gain. Entropy measures the impurity of a set, it assigns high uncertainty values to outcomes with low probability and low uncertainty values to outcomes with high probability. The information gain of an attribute is the reduction in entropy from partitioning the data according to an attribute. This helps partition the nodes of the tree by making the attribute with the highest information gain the root node and so on as you progress down the tree, the information gain of the attributes decreases, until there is no attributes left then we finish with the leaf nodes. Information gain has some drawbacks for example it tends to favour attributes that can take on a large number of different values. An alternative is the information gain ratio. \n",
    "\n",
    "There are some issues with decision tree learning such as a decision tree cannot consider relationships between two attributes and it doesn’t deal well with “noisy” data, missing attributes. The hypothesis found is sensitive to the training set. If you were to replace some training set data with new ones, the new one would be consistent with the original tree. Modifications to reduce this instability would be to alter the attribute selection procedure so that it is less sensitive to some of the training set data being replaced. [1][2][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ae5110",
   "metadata": {},
   "source": [
    "<h3>Naïve Bayes</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c4e883",
   "metadata": {},
   "source": [
    "The second classification algorithm we will discuss that was applied to the dataset is Naïve Bayes algorithm. This algorithm is based around Bayes Theorem which calculates the probability of an event occurring based on prior knowledge that represents uncertainty before seeing any data. This theorem uses conditional probability which means events are mutually exclusive and can’t occur together i.e every attribute in the dataset is treated as independent of each other, knowing the Clump Thickness value of a tumor gives us no information on its Marginal Adhesion and vice versa. This assumption is why the algorithm is known as “naïve”. The other assumption with this algorithm is that every attribute is equal, all of them combined make an accurate output. There is no attribute with greater importance than the other attributes like we saw in the J48 algorithm. \n",
    "\n",
    "The process of this algorithm starts by analysing the data in a frequency table. Then you plug in the data to bayes theorem to get the posterior which is the probability distribution that represents uncertainty after seeing the data. The attribute with the highest posterior decides the outcome of prediction, this creates a classifier model. Naïve Bayes is much more faster than other algorithms and can be applied to smaller training sets. When its assumption of independence holds, it performs much better than other models. However in real life most attributes are dependent on each other so this would decrease the accuracy in its performance. An example of the use of this algorithm in the real world is in spam filtering where it identifies spam in your email.[1][13][14][15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb530f49",
   "metadata": {},
   "source": [
    "<h3> Multilayer Perceptron </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a484ce55",
   "metadata": {},
   "source": [
    "The third algorithm mentioned in this research paper is multilayer perceptron. This algorithm has a structure of three main layers, the input layer, the hidden layer and the output layer. A dataset is processed through this algorithm by passing into the input layer first then the hidden layer and finally through the output layer. \n",
    "\n",
    "A Multilayer Perceptron(MLP) is a neural network and each neuron has inputs that are weighted. Each of these weights are given values, the larger the values the more complicated the network therefore it is favourable to keep the values small. The weights are adjusted during training after the actual results are compared with the expected results to try get them as close as possible. The hidden layer and output layer are where most of the computations occur in this approximation function. MLP’s have an activation function that is used to map the weighted inputs to outputs of the network.[1][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87d2302",
   "metadata": {},
   "source": [
    "<h3> K-Nearest Neighbor(KNN) </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35a35f5",
   "metadata": {},
   "source": [
    "K-Nearest Neighbors is another classification algorithm looked at in this research paper. This algorithm is easy to use and implement. The methodology of KNN is to measure similarity between all the data points in a dataset. To visualise this concept, imagine you plot all the data on a graph and then you used a distance metric to calculate the distance between each data point from another. Then you chose how many clusters you want the data to be grouped into and the algorithm assigns each data point a cluster based on how similar it is to other data points in that cluster. For example if cluster 1 has data points with \"Clump Thickness\" of around 7/8 then a data point with a \"Clump Thickness\" of value 8 would be put into the same cluster but of it had a value of 5 it would be put in a different cluster.\n",
    "\n",
    "KNN is a versatile algorithm as it can be used in both classification and regression. However it proves to be impractical when dealing with a larger number of data as it slows down in comparison to other algorithms. An example of KNN applications in the real world would be when Netflix recommends movies to a user based on previous movies the user has watched and enjoyed, it searches for similar movies.[1][16]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1b5775",
   "metadata": {},
   "source": [
    "<h3> Support Vector Machine(SVM) </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6da8af",
   "metadata": {},
   "source": [
    "The final classification algorithm we will discuss is the Support Vector Machine(SVM) algorithm. This machine learning algorithm produced the most accurate results in this research paper. The algorithm splits up the data points using hyperplanes with n-dimensions where n is the number of classifiers the dataset has. Since our dataset has two classification types, benign or malignant then our hyperplane will be 2 dimensional(a line). It aims to get the largest possible margin between different target classes i.e the maximum space between the location of the different types of classification outputs.\n",
    "\n",
    "This supervised learning algorithm uses the pre-labelled dataset to plot all the data points and find the optimal hyperplane. The performance of this algorithm depends on how optimal the hyperplane is. Data points that are closest to the margin are called support vectors and they are used create the hyperplane and decide on how to get the maximum margin. SVM is a high performing algorithm especially with a large margin however it does not perform well with small margins as it makes it hard to distinguish between different classes.[1][17][18]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aacc970",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8147bcc8",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#4169E1;\"> Statistical Analysis Of The Dataset </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bd4610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necessary Packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26248f68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample code number</th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample code number   Clump Thickness  Uniformity of Cell Size  \\\n",
       "0              1000025                5                        1   \n",
       "1              1002945                5                        4   \n",
       "2              1015425                3                        1   \n",
       "3              1016277                6                        8   \n",
       "4              1017023                4                        1   \n",
       "\n",
       "   Uniformity of Cell Shape  Marginal Adhesion  Single Epithelial Cell Size  \\\n",
       "0                         1                  1                            2   \n",
       "1                         4                  5                            7   \n",
       "2                         1                  1                            2   \n",
       "3                         8                  1                            3   \n",
       "4                         1                  3                            2   \n",
       "\n",
       "  Bare Nuclei  Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
       "0           1                3                1        1      2  \n",
       "1          10                3                2        1      2  \n",
       "2           2                3                1        1      2  \n",
       "3           4                3                7        1      2  \n",
       "4           1                3                1        1      2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in csv file containing the data\n",
    "dataset = pd.read_csv(\"breast-cancer-wisconsin.csv\",encoding='latin1')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4553411c",
   "metadata": {},
   "source": [
    "First we need to remove missing values from the dataset. In the documentation provided with the dataset it was noted that there were 16 missing values under the Bare Nuclei column therefore I have decided to locate these rows and delete that entire row to prevent these missing values from causing bias or effecting accurate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b9c6909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample code number</th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1057013</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1096800</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>?</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1183246</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1184840</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1193683</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1197510</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>1241232</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>169356</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>432809</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>563649</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>606140</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>61634</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>704168</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>?</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>733639</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1238464</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>1057067</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sample code number   Clump Thickness  Uniformity of Cell Size  \\\n",
       "23               1057013                8                        4   \n",
       "40               1096800                6                        6   \n",
       "139              1183246                1                        1   \n",
       "145              1184840                1                        1   \n",
       "158              1193683                1                        1   \n",
       "164              1197510                5                        1   \n",
       "235              1241232                3                        1   \n",
       "249               169356                3                        1   \n",
       "275               432809                3                        1   \n",
       "292               563649                8                        8   \n",
       "294               606140                1                        1   \n",
       "297                61634                5                        4   \n",
       "315               704168                4                        6   \n",
       "321               733639                3                        1   \n",
       "411              1238464                1                        1   \n",
       "617              1057067                1                        1   \n",
       "\n",
       "     Uniformity of Cell Shape  Marginal Adhesion  Single Epithelial Cell Size  \\\n",
       "23                          5                  1                            2   \n",
       "40                          6                  9                            6   \n",
       "139                         1                  1                            1   \n",
       "145                         3                  1                            2   \n",
       "158                         2                  1                            3   \n",
       "164                         1                  1                            2   \n",
       "235                         4                  1                            2   \n",
       "249                         1                  1                            2   \n",
       "275                         3                  1                            2   \n",
       "292                         8                  1                            2   \n",
       "294                         1                  1                            2   \n",
       "297                         3                  1                            2   \n",
       "315                         5                  6                            7   \n",
       "321                         1                  1                            2   \n",
       "411                         1                  1                            1   \n",
       "617                         1                  1                            1   \n",
       "\n",
       "    Bare Nuclei  Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
       "23            ?                7                3        1      4  \n",
       "40            ?                7                8        1      2  \n",
       "139           ?                2                1        1      2  \n",
       "145           ?                2                1        1      2  \n",
       "158           ?                1                1        1      2  \n",
       "164           ?                3                1        1      2  \n",
       "235           ?                3                1        1      2  \n",
       "249           ?                3                1        1      2  \n",
       "275           ?                2                1        1      2  \n",
       "292           ?                6               10        1      4  \n",
       "294           ?                2                1        1      2  \n",
       "297           ?                2                3        1      2  \n",
       "315           ?                4                9        1      2  \n",
       "321           ?                3                1        1      2  \n",
       "411           ?                2                1        1      2  \n",
       "617           ?                1                1        1      2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the rows where Bare Nuclei is equal to ?\n",
    "missing_values=dataset.loc[dataset.loc[:,'Bare Nuclei']=='?']\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6524046c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove rows containing missing values\n",
    "dataset.drop([23,40,139,145,158,164,235,249,275,292,294,297,315,321,411,617], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff6bfb28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1      10\n",
       "2       2\n",
       "3       4\n",
       "4       1\n",
       "       ..\n",
       "694     2\n",
       "695     1\n",
       "696     3\n",
       "697     4\n",
       "698     5\n",
       "Name: Bare Nuclei, Length: 683, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the Bare Nuclei column now\n",
    "dataset.loc[:,'Bare Nuclei']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531a0ce6",
   "metadata": {},
   "source": [
    "The Bare Nuclei column now has 683 rows after we deleted the missing value rows but the column has data type object. We need to change this in order to be able to do statistical analysis on the column.[7][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "944ce848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change column to type int \n",
    "dataset['Bare Nuclei'] = dataset['Bare Nuclei'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76d7ed50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample code number</th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.830000e+02</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.076720e+06</td>\n",
       "      <td>4.442167</td>\n",
       "      <td>3.150805</td>\n",
       "      <td>3.215227</td>\n",
       "      <td>2.830161</td>\n",
       "      <td>3.234261</td>\n",
       "      <td>3.544656</td>\n",
       "      <td>3.445095</td>\n",
       "      <td>2.869693</td>\n",
       "      <td>1.603221</td>\n",
       "      <td>2.699854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.206440e+05</td>\n",
       "      <td>2.820761</td>\n",
       "      <td>3.065145</td>\n",
       "      <td>2.988581</td>\n",
       "      <td>2.864562</td>\n",
       "      <td>2.223085</td>\n",
       "      <td>3.643857</td>\n",
       "      <td>2.449697</td>\n",
       "      <td>3.052666</td>\n",
       "      <td>1.732674</td>\n",
       "      <td>0.954592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.337500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.776170e+05</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.171795e+06</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.238705e+06</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.345435e+07</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sample code number   Clump Thickness  Uniformity of Cell Size  \\\n",
       "count         6.830000e+02       683.000000               683.000000   \n",
       "mean          1.076720e+06         4.442167                 3.150805   \n",
       "std           6.206440e+05         2.820761                 3.065145   \n",
       "min           6.337500e+04         1.000000                 1.000000   \n",
       "25%           8.776170e+05         2.000000                 1.000000   \n",
       "50%           1.171795e+06         4.000000                 1.000000   \n",
       "75%           1.238705e+06         6.000000                 5.000000   \n",
       "max           1.345435e+07        10.000000                10.000000   \n",
       "\n",
       "       Uniformity of Cell Shape  Marginal Adhesion  \\\n",
       "count                683.000000         683.000000   \n",
       "mean                   3.215227           2.830161   \n",
       "std                    2.988581           2.864562   \n",
       "min                    1.000000           1.000000   \n",
       "25%                    1.000000           1.000000   \n",
       "50%                    1.000000           1.000000   \n",
       "75%                    5.000000           4.000000   \n",
       "max                   10.000000          10.000000   \n",
       "\n",
       "       Single Epithelial Cell Size  Bare Nuclei  Bland Chromatin  \\\n",
       "count                   683.000000   683.000000       683.000000   \n",
       "mean                      3.234261     3.544656         3.445095   \n",
       "std                       2.223085     3.643857         2.449697   \n",
       "min                       1.000000     1.000000         1.000000   \n",
       "25%                       2.000000     1.000000         2.000000   \n",
       "50%                       2.000000     1.000000         3.000000   \n",
       "75%                       4.000000     6.000000         5.000000   \n",
       "max                      10.000000    10.000000        10.000000   \n",
       "\n",
       "       Normal Nucleoli     Mitoses       Class  \n",
       "count       683.000000  683.000000  683.000000  \n",
       "mean          2.869693    1.603221    2.699854  \n",
       "std           3.052666    1.732674    0.954592  \n",
       "min           1.000000    1.000000    2.000000  \n",
       "25%           1.000000    1.000000    2.000000  \n",
       "50%           1.000000    1.000000    2.000000  \n",
       "75%           4.000000    1.000000    4.000000  \n",
       "max          10.000000   10.000000    4.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0400cd1b",
   "metadata": {},
   "source": [
    "Using the .describe() function we get the statistics table above from which we can gain useful information about the dataset.\n",
    "\n",
    "The \"count\" row shows us the number of rows under each column, the \"mean\" gives us the average value, \"std\" stands for standard deviation of values in each column, \"min\" shows the smallest value recorded, \"25%\" and \"50%\" and \"75%\" are all percentiles where \"50%\" is also called the median and lastly \"max\" stands for the largest value in each column.\n",
    "\n",
    "This summary of the dataset tells us there are 683 rows under each column therefore there are no values missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52e34902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sample code number             444\n",
       "Clump Thickness                444\n",
       "Uniformity of Cell Size        444\n",
       "Uniformity of Cell Shape       444\n",
       "Marginal Adhesion              444\n",
       "Single Epithelial Cell Size    444\n",
       "Bare Nuclei                    444\n",
       "Bland Chromatin                444\n",
       "Normal Nucleoli                444\n",
       "Mitoses                        444\n",
       "Class                          444\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset.loc locates all the columns where class is equal to 2\n",
    "benign=dataset.loc[dataset.loc[:,'Class']==2]\n",
    "benign.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7ec7570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sample code number             239\n",
       "Clump Thickness                239\n",
       "Uniformity of Cell Size        239\n",
       "Uniformity of Cell Shape       239\n",
       "Marginal Adhesion              239\n",
       "Single Epithelial Cell Size    239\n",
       "Bare Nuclei                    239\n",
       "Bland Chromatin                239\n",
       "Normal Nucleoli                239\n",
       "Mitoses                        239\n",
       "Class                          239\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset.loc locates all the columns where class is equal to 4\n",
    "malignant=dataset.loc[dataset.loc[:,'Class']==4]\n",
    "malignant.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6640fa9f",
   "metadata": {},
   "source": [
    "Using the functions .loc and .count() we can see there are 444 rows of the dataset where class equals 2 which stands for the benign tumors. There are 239 cases where the tumor is malignant. We can do a quick check to make sure that all the benign rows contain only the value 2 and all the malignant rows contain only the value 4 by using max and min functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "681917b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum and minimum values recorded in the Class column for benign cases are 2 and 2\n"
     ]
    }
   ],
   "source": [
    "#get the max and min values for benign cases\n",
    "print(\"The maximum and minimum values recorded in the Class column for benign cases are\",\n",
    "      benign['Class'].min(),\"and\",benign['Class'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2923387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum and minimum values recorded in the Class column for malignant cases are 4 and 4\n"
     ]
    }
   ],
   "source": [
    "#get the max and min values for malignant cases\n",
    "print(\"The maximum and minimum values recorded in the Class column for malignant cases are\",\n",
    "      malignant['Class'].min(),\"and\",malignant['Class'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9acc7c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sample code number             1115261.01\n",
       "Clump Thickness                      2.96\n",
       "Uniformity of Cell Size              1.31\n",
       "Uniformity of Cell Shape             1.41\n",
       "Marginal Adhesion                    1.35\n",
       "Single Epithelial Cell Size          2.11\n",
       "Bare Nuclei                          1.35\n",
       "Bland Chromatin                      2.08\n",
       "Normal Nucleoli                      1.26\n",
       "Mitoses                              1.07\n",
       "Class                                2.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the mean values for benign tumors\n",
    "#numeric_only=True stops the function producing a warning [5]\n",
    "#round(,2) round results to 2 decimal places [6]\n",
    "round(benign.mean(numeric_only=True),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1a55870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sample code number             1005121.44\n",
       "Clump Thickness                      7.19\n",
       "Uniformity of Cell Size              6.58\n",
       "Uniformity of Cell Shape             6.56\n",
       "Marginal Adhesion                    5.59\n",
       "Single Epithelial Cell Size          5.33\n",
       "Bare Nuclei                          7.63\n",
       "Bland Chromatin                      5.97\n",
       "Normal Nucleoli                      5.86\n",
       "Mitoses                              2.60\n",
       "Class                                4.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the mean values for malignant tumors\n",
    "#numeric_only=True stops the function producing a warning [5]\n",
    "#round(,2) round results to 2 decimal places [6]\n",
    "round(malignant.mean(numeric_only=True),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1e1ee98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clump Thickness                4.24\n",
       "Uniformity of Cell Size        5.25\n",
       "Uniformity of Cell Shape       5.13\n",
       "Marginal Adhesion              4.23\n",
       "Single Epithelial Cell Size    3.21\n",
       "Bare Nuclei                    6.28\n",
       "Bland Chromatin                3.87\n",
       "Normal Nucleoli                4.60\n",
       "Mitoses                        1.55\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#minus the means to look at the difference\n",
    "difference=round(malignant[1:-1].mean(numeric_only=True),2) - round(benign.mean(numeric_only=True),2)\n",
    "#get rid of columns that dont give us much information\n",
    "difference.drop(['Sample code number ','Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa28074",
   "metadata": {},
   "source": [
    "<h4>Analysis of the means</h4>\n",
    "On intial observation of the mean values for all the attributes beloning to benign tumours vs. maligant tumours, it is clear that all values for malignant tumors are greater than for benign. This makes sense since malignant tumors grow uncontrollably and they spread to other parts of the body whereas benign tumors tend to stay put and not spread out while growing slowly over time. After calculating the difference in the means you can see the biggest difference is in the Bare Nuclei with a difference of 6.28. Perhaps this attribute is the easiest attribute to use to distinguish between the two types of tumor and also predict the type. The least obvious attribute appears to be mitosis with a difference of 1.55 so I would guess that this attribute doesn't have much influence/weight in the model used to predict the types of tumor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdef390a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Clump Thickness</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.642481</td>\n",
       "      <td>0.653470</td>\n",
       "      <td>0.487829</td>\n",
       "      <td>0.523596</td>\n",
       "      <td>0.593091</td>\n",
       "      <td>0.553742</td>\n",
       "      <td>0.534066</td>\n",
       "      <td>0.350957</td>\n",
       "      <td>0.714790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <td>0.642481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.907228</td>\n",
       "      <td>0.706977</td>\n",
       "      <td>0.753544</td>\n",
       "      <td>0.691709</td>\n",
       "      <td>0.755559</td>\n",
       "      <td>0.719346</td>\n",
       "      <td>0.460755</td>\n",
       "      <td>0.820801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <td>0.653470</td>\n",
       "      <td>0.907228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.685948</td>\n",
       "      <td>0.722462</td>\n",
       "      <td>0.713878</td>\n",
       "      <td>0.735344</td>\n",
       "      <td>0.717963</td>\n",
       "      <td>0.441258</td>\n",
       "      <td>0.821891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <td>0.487829</td>\n",
       "      <td>0.706977</td>\n",
       "      <td>0.685948</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.594548</td>\n",
       "      <td>0.670648</td>\n",
       "      <td>0.668567</td>\n",
       "      <td>0.603121</td>\n",
       "      <td>0.418898</td>\n",
       "      <td>0.706294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <td>0.523596</td>\n",
       "      <td>0.753544</td>\n",
       "      <td>0.722462</td>\n",
       "      <td>0.594548</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.585716</td>\n",
       "      <td>0.618128</td>\n",
       "      <td>0.628926</td>\n",
       "      <td>0.480583</td>\n",
       "      <td>0.690958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <td>0.593091</td>\n",
       "      <td>0.691709</td>\n",
       "      <td>0.713878</td>\n",
       "      <td>0.670648</td>\n",
       "      <td>0.585716</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.680615</td>\n",
       "      <td>0.584280</td>\n",
       "      <td>0.339210</td>\n",
       "      <td>0.822696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <td>0.553742</td>\n",
       "      <td>0.755559</td>\n",
       "      <td>0.735344</td>\n",
       "      <td>0.668567</td>\n",
       "      <td>0.618128</td>\n",
       "      <td>0.680615</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.665602</td>\n",
       "      <td>0.346011</td>\n",
       "      <td>0.758228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <td>0.534066</td>\n",
       "      <td>0.719346</td>\n",
       "      <td>0.717963</td>\n",
       "      <td>0.603121</td>\n",
       "      <td>0.628926</td>\n",
       "      <td>0.584280</td>\n",
       "      <td>0.665602</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.433757</td>\n",
       "      <td>0.718677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mitoses</th>\n",
       "      <td>0.350957</td>\n",
       "      <td>0.460755</td>\n",
       "      <td>0.441258</td>\n",
       "      <td>0.418898</td>\n",
       "      <td>0.480583</td>\n",
       "      <td>0.339210</td>\n",
       "      <td>0.346011</td>\n",
       "      <td>0.433757</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.423448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>0.714790</td>\n",
       "      <td>0.820801</td>\n",
       "      <td>0.821891</td>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.690958</td>\n",
       "      <td>0.822696</td>\n",
       "      <td>0.758228</td>\n",
       "      <td>0.718677</td>\n",
       "      <td>0.423448</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Clump Thickness  Uniformity of Cell Size  \\\n",
       "Clump Thickness                     1.000000                 0.642481   \n",
       "Uniformity of Cell Size             0.642481                 1.000000   \n",
       "Uniformity of Cell Shape            0.653470                 0.907228   \n",
       "Marginal Adhesion                   0.487829                 0.706977   \n",
       "Single Epithelial Cell Size         0.523596                 0.753544   \n",
       "Bare Nuclei                         0.593091                 0.691709   \n",
       "Bland Chromatin                     0.553742                 0.755559   \n",
       "Normal Nucleoli                     0.534066                 0.719346   \n",
       "Mitoses                             0.350957                 0.460755   \n",
       "Class                               0.714790                 0.820801   \n",
       "\n",
       "                             Uniformity of Cell Shape  Marginal Adhesion  \\\n",
       "Clump Thickness                              0.653470           0.487829   \n",
       "Uniformity of Cell Size                      0.907228           0.706977   \n",
       "Uniformity of Cell Shape                     1.000000           0.685948   \n",
       "Marginal Adhesion                            0.685948           1.000000   \n",
       "Single Epithelial Cell Size                  0.722462           0.594548   \n",
       "Bare Nuclei                                  0.713878           0.670648   \n",
       "Bland Chromatin                              0.735344           0.668567   \n",
       "Normal Nucleoli                              0.717963           0.603121   \n",
       "Mitoses                                      0.441258           0.418898   \n",
       "Class                                        0.821891           0.706294   \n",
       "\n",
       "                             Single Epithelial Cell Size  Bare Nuclei  \\\n",
       "Clump Thickness                                 0.523596     0.593091   \n",
       "Uniformity of Cell Size                         0.753544     0.691709   \n",
       "Uniformity of Cell Shape                        0.722462     0.713878   \n",
       "Marginal Adhesion                               0.594548     0.670648   \n",
       "Single Epithelial Cell Size                     1.000000     0.585716   \n",
       "Bare Nuclei                                     0.585716     1.000000   \n",
       "Bland Chromatin                                 0.618128     0.680615   \n",
       "Normal Nucleoli                                 0.628926     0.584280   \n",
       "Mitoses                                         0.480583     0.339210   \n",
       "Class                                           0.690958     0.822696   \n",
       "\n",
       "                             Bland Chromatin  Normal Nucleoli   Mitoses  \\\n",
       "Clump Thickness                     0.553742         0.534066  0.350957   \n",
       "Uniformity of Cell Size             0.755559         0.719346  0.460755   \n",
       "Uniformity of Cell Shape            0.735344         0.717963  0.441258   \n",
       "Marginal Adhesion                   0.668567         0.603121  0.418898   \n",
       "Single Epithelial Cell Size         0.618128         0.628926  0.480583   \n",
       "Bare Nuclei                         0.680615         0.584280  0.339210   \n",
       "Bland Chromatin                     1.000000         0.665602  0.346011   \n",
       "Normal Nucleoli                     0.665602         1.000000  0.433757   \n",
       "Mitoses                             0.346011         0.433757  1.000000   \n",
       "Class                               0.758228         0.718677  0.423448   \n",
       "\n",
       "                                Class  \n",
       "Clump Thickness              0.714790  \n",
       "Uniformity of Cell Size      0.820801  \n",
       "Uniformity of Cell Shape     0.821891  \n",
       "Marginal Adhesion            0.706294  \n",
       "Single Epithelial Cell Size  0.690958  \n",
       "Bare Nuclei                  0.822696  \n",
       "Bland Chromatin              0.758228  \n",
       "Normal Nucleoli              0.718677  \n",
       "Mitoses                      0.423448  \n",
       "Class                        1.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#delete Sample code number and class column since they dont apply to this table\n",
    "new_dataset=dataset.drop(['Sample code number '],axis=1)\n",
    "#get the correlation between all the columns\n",
    "new_dataset.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603bbed3",
   "metadata": {},
   "source": [
    "<h4>Relationships Between Attributes</h4>\n",
    "The table above shows the correlation between each of the attributes. The two attributes with the strongest correlation are Uniformity of Cell Size and Uniformity of Cell Shape, they have a strong positive correlation of 0.907 which is very close to 1. The weakest relationship seems to be between Mitoses and Bare Nuclei with a correlation coefficient of 0.339. When analysing the difference between the means of the two types of tumour above I made an assumption that mitosis would have least weight when predicting tumors and this table helps confirm that assumption as all of the correlation coefficients belonging to mitosis with the other attributes appear to be quite weak. They are all under 0.5 suggesting that mitosis doesn't have much of an effect on the other values.\n",
    "\n",
    "Sample code number column was removed since it tell us nothing about the type of tumor and also the class column is a result of all the attributes so we know it has a strong relationship with all variables but we can't measure the relationship properly since it has discrete values 2 or 4. Therefore Class column was removed aswell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d7f778",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b208587",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#4169E1;\"> Machine Learning Algorithms </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f19e64c",
   "metadata": {},
   "source": [
    "Next we can look at some machine learning classifiers and train them on our wisconsin breast cancer dataset. Once the classification models are trained we can test the models using a test set that will be set aside from the dataset and we can see the accuracy at which our models performed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439fac26",
   "metadata": {},
   "source": [
    "<h4> Inputs/Outputs </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a175cc3",
   "metadata": {},
   "source": [
    "First we must import packages we will need to use and then define what columns are the input values used to predict the chosen output and the output values which are the labels that classify the data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3388ce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages \n",
    "import sklearn.neighbors as nei\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38a47a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#State the columns used as inputs - attributes and the column used as outputs -to classify the tumor\n",
    "inputs=dataset[['Clump Thickness','Uniformity of Cell Size','Uniformity of Cell Shape','Marginal Adhesion',\n",
    "        'Single Epithelial Cell Size','Bare Nuclei','Bland Chromatin','Normal Nucleoli','Mitoses']]\n",
    "outputs=dataset['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d5b045",
   "metadata": {},
   "source": [
    "Next we will take out a proportion of the dataset and set it aside for testing before we start training our model. We do this because we want to test our model on data it has never seen before. For this model I chose to set aside 20% of the dataset for testing, I chose the parameter after some trial and error with different values and it provided the best accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cfab6297",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into train and test data\n",
    "#test_size is how much of the dataset to set aside for testing which is set at 20% so 80% is used for training the model\n",
    "#random_state = 10 means no. of shuffles- we will get the same results if we run this code again instead of resetting each time\n",
    "#stratify = outputs means make sure the result produces the same proportion of malignant vs benign as in the original dataset\n",
    "inputs, inputs_test, outputs, outputs_test = train_test_split(inputs, outputs, test_size=0.2, random_state=10, stratify=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf828c9",
   "metadata": {},
   "source": [
    "<h3> K-Nearest Neighbors</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73c1ee6",
   "metadata": {},
   "source": [
    "<h4> Classifier </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b8c11a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use k-nearest neighbours scikit learn model and set n neighbours as 5\n",
    "knn = nei.KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d7d410b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit out split dataset into the model\n",
    "knn.fit(inputs,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b3a7e69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 4, 4, 2], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show first 5 model predictions on the test data\n",
    "knn.predict(inputs_test)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "40bcdd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9857142857142858"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check accuracy of our model on the test data\n",
    "knn.score(inputs_test, outputs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2516e9",
   "metadata": {},
   "source": [
    "The accuracy score we got was 0.9708 with the number of neighbors set to 5 which was a randomly chosen parameter. Next I decided to use GridSearch to find out what the best number for the n_neighbors parameter would be.[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "691dd88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24])})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create new a knn model\n",
    "new_knn = nei.KNeighborsClassifier()\n",
    "#create a dictionary of all values we want to test for n_neighbors\n",
    "param_grid = {'n_neighbors': np.arange(1, 25)}\n",
    "#use gridsearch to test all values for n_neighbors\n",
    "knn_gscv = GridSearchCV(new_knn, param_grid, cv=5)\n",
    "#fit model to data\n",
    "knn_gscv.fit(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6872c8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 8}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for the optimal n_neighbors value\n",
    "knn_gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f5a36634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9714285714285714"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use k-nearest neighbours scikit learn model and set n neighbours as 9\n",
    "knn = nei.KNeighborsClassifier(n_neighbors=8)\n",
    "\n",
    "#enter split dataset into the model\n",
    "knn.fit(inputs,outputs)\n",
    "\n",
    "#check accuracy of our model on the test data\n",
    "knn.score(inputs_test, outputs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e663aa3b",
   "metadata": {},
   "source": [
    "The result I got was that the highest accuracy achieved was with 8 nearest neighbors and had a value of 0.9714. This seems to be inaccurate since the accuracy score I got with my first model was higher. So instead I decided to write a quick function that calculates the accuracy score of the model for the n_neighbor parameter equal to values 2-24 and outputs the accuracy score for each value into an array. We can then see which value produces the highest accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "45f81c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9571428571428572] [0.9428571428571428] [0.9714285714285714] [0.9571428571428572] [0.9857142857142858] [0.9857142857142858] [0.9857142857142858] [0.9714285714285714] [0.9714285714285714] [0.9714285714285714] [0.9714285714285714] [0.9714285714285714] [0.9714285714285714] [0.9714285714285714] [0.9714285714285714] [0.9714285714285714] [0.9714285714285714] [0.9714285714285714] [0.9714285714285714] [0.9714285714285714] [0.9714285714285714] [0.9714285714285714] [0.9714285714285714] [0.9714285714285714] "
     ]
    }
   ],
   "source": [
    "#for all values from 2 to 24\n",
    "for i in range (1, 25):\n",
    "    #empty array to fill with scores\n",
    "    acc_score=[]\n",
    "    # train and fit model to dataset\n",
    "    knn = nei.KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(inputs,outputs)\n",
    "    score = knn.score(inputs_test, outputs_test)\n",
    "    #add all scores to empty array\n",
    "    acc_score.append(score)\n",
    "    #print results\n",
    "    print(acc_score, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5afa4eb",
   "metadata": {},
   "source": [
    "A value of 5,6 or 7 all give the highest accuracy scores for n_neighbor parameter so I will just use my first knn model with 5 nearest neighbors as my final model with an accuracy score of 0.9857."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047691f4",
   "metadata": {},
   "source": [
    "<h3> Support Vector Machine </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958c3442",
   "metadata": {},
   "source": [
    "<h4> Classifier </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "85a913ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create model\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5b5166b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict values\n",
    "y_pred = svclassifier.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3bf4fc8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9857142857142858"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check accuracy of our model on the test data\n",
    "svclassifier.score(inputs_test, outputs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4f6055",
   "metadata": {},
   "source": [
    "After training and testing the support vector machine model on the data we get an accuracy score of 0.9857 which is very good. For this model I chose a linear kernel at random. Next I will look at the results for different values of the kernel parameter.[20][21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b1e0010b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9857142857142858] [0.9714285714285714] [0.5285714285714286] "
     ]
    }
   ],
   "source": [
    "#create an array of different kernels\n",
    "kernel=['linear', 'poly', 'sigmoid']\n",
    "\n",
    "#for each kernel in the array\n",
    "for i in kernel:\n",
    "    #empty array to fill with scores\n",
    "    acc_score=[]\n",
    "    #train the model on diff kernels\n",
    "    svclassifier = SVC(kernel=i)\n",
    "    svclassifier.fit(inputs, outputs)\n",
    "    y_pred = svclassifier.predict(inputs)\n",
    "    score=svclassifier.score(inputs_test, outputs_test)\n",
    "    #append all the scores into the empty scores array\n",
    "    acc_score.append(score)\n",
    "    #print results\n",
    "    print(acc_score, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a29c9c9",
   "metadata": {},
   "source": [
    "The linear kernel still seems to perform the best in comparison to polynomial and sigmoid. In order to test the radius basis function(rbf) kernel we need a gamma parameter and a C parameter. Gamma defines how far a training example reaches and C stands for the regularization parameter. A small value for C gives a larger margin and a large value for C gives a small margin.[19] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a0d953b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal parameters are {'C': 0.1, 'gamma': 0.01} with a score of 0.98\n"
     ]
    }
   ],
   "source": [
    "#generate a range of c values\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "#generate a range of gamma values\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "#create a dictionary of all values we want to test for gamma and c\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "cv = StratifiedShuffleSplit(test_size=0.2, random_state=10)\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid, cv=cv)\n",
    "grid.fit(inputs, outputs)\n",
    "\n",
    "print(\"The optimal parameters are %s with a score of %0.2f\"% (grid.best_params_, grid.best_score_)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d66bd2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rbf kernel:  0.9857142857142858\n"
     ]
    }
   ],
   "source": [
    "svclassifier = SVC(kernel='rbf', C=0.1,gamma=0.01)\n",
    "svclassifier.fit(inputs, outputs)\n",
    "print(\"rbf kernel: \",svclassifier.score(inputs_test, outputs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "82b91f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid kernel: 0.6428571428571429\n"
     ]
    }
   ],
   "source": [
    "svclassifier = SVC(kernel='sigmoid', C=0.1,gamma=0.01)\n",
    "svclassifier.fit(inputs, outputs)\n",
    "print(\"sigmoid kernel:\",svclassifier.score(inputs_test, outputs_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65a09ed",
   "metadata": {},
   "source": [
    "After testing the model with various options for the kernel parameter, it appears that both linear and radial basis function kernels perform the best as they both have an accuracy score of 0.9857."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61f4175",
   "metadata": {},
   "source": [
    "<h3>Naïve Bayes</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b753bb10",
   "metadata": {},
   "source": [
    "<h4>Classifier</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "21bec318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create and fit model\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fdda7909",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict values\n",
    "y_pred = gnb.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "42fc3ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9857142857142858"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check accuracy of our model on the test data\n",
    "gnb.score(inputs_test, outputs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2e2b8e",
   "metadata": {},
   "source": [
    "The naïve bayes model gave the same accuracy results the both the other two models achieved which was 0.9857. This is quite unusual and can only mean that I have overfitted my data because this is a very high score achieved exactly the same by the three models. When trying out different values for parameters some of the test data must have been leaked into the training set and the model was then never exposed to many inputs that it had never seen before.\n",
    "\n",
    "After doing some research I found a method called cross validation that helps stop your models overfitting the data. This method shuffles the data and the training data is split into k groups(I split it into 10 folds), trainied on k-1 groups and the model is tested on the remaining group. The average accuracy score is calculated for each loop and the mean of the accuracy scores is returned.[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "292108fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: Mean Accuracy = 96.75%\n",
      "SVM: Mean Accuracy = 97.83%\n",
      "Naive Bayes: Mean Accuracy = 97.09%\n"
     ]
    }
   ],
   "source": [
    "#[23] create an array of all the models and their parameters\n",
    "models=[('KNN', nei.KNeighborsClassifier(n_neighbors=5)),(('SVM', SVC(kernel='rbf', C=0.1,gamma=0.01))),(('Naive Bayes', GaussianNB()))]\n",
    "\n",
    "#loop through all the models and perform cross validation on the data before inserting it to the models\n",
    "for name, model in models:\n",
    "    #use 10 folds and set random state to get same results when rerun, shuffle the data\n",
    "    kfold = KFold(n_splits=10, random_state=15,shuffle=True)\n",
    "    #train the models using cross validation\n",
    "    result = cross_val_score(model, inputs, outputs, cv=kfold, scoring='accuracy')\n",
    "    #print the results\n",
    "    print(\"%s: Mean Accuracy = %.2f%%\" % (name, result.mean()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce9a0ae",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#4169E1;\">Evaluation Of Results </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c37948e",
   "metadata": {},
   "source": [
    "The three models I have chosen perform very well on the Wisconsin breast cancer dataset. The Support Vector Machine model produced the highest accuracy score, similar to the research paper mentioned at the beginning of this project. SVM was followed by K-Nearest Neighbors and then the lowest accuracy score was achieved by the Naïve Bayes model. Even though the Naïve Bayes model performed quite well it was based on the assumption that the attributes were independent when we saw in the statistical analysis section that most are dependent on each other, this would make a less preferred classification model. \n",
    "\n",
    "Computing these test results was done fairly by using the same split for testing and for training. The same dataset and epoch were used to ensure an unbiased comparison. Furthermore, although cross-validation is a good way of estimating likely future performance of a model, to fully evaluate the models I believe we need a larger dataset to be able to train the models sufficiently while also have plenty of data to keep aside for further testing on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b691472d",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231d64d3",
   "metadata": {},
   "source": [
    "[1] https://www.hindawi.com/journals/abb/2022/6187275/ <br>\n",
    "[2] https://towardsdatascience.com/decision-trees-for-classification-id3-algorithm-explained-89df76e72df1 <br>\n",
    "[3] https://en.wikipedia.org/w/index.php?title=ID3_algorithm&oldid=970826747 <br>\n",
    "[4] https://machinelearningmastery.com/neural-networks-crash-course/ <br>\n",
    "[5] https://stackoverflow.com/questions/70897794/finding-the-mean-of-nuisance-columns-in-dataframe-error <br>\n",
    "[6] https://stackoverflow.com/questions/20457038/how-to-round-to-2-decimals-with-python <br>\n",
    "[7] https://sparkbyexamples.com/pandas/pandas-convert-column-to-int/#:~:text=Convert%20Column%20to%20int%20(Integer,int64%20%2C%20numpy. <br>\n",
    "[8] https://www.freecodecamp.org/news/drop-list-of-rows-from-pandas-dataframe/#:~:text=To%20drop%20a%20row%20or%20column%20in%20a%20dataframe%2C%20you,method%20in%20the%20docs%20here.&text=Rows%20are%20labelled%20using%20the,starting%20with%200%2C%20by%20default. <br>\n",
    "[9] https://towardsdatascience.com/building-a-k-nearest-neighbors-k-nn-model-with-scikit-learn-51209555453a<br>\n",
    "[10] https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html <br>\n",
    "[11] https://www.kaggle.com/datasets/ninjacoding/breast-cancer-wisconsin-benign-or-malignant <br>\n",
    "[12] https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)<br>\n",
    "[13] https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/<br>\n",
    "[14] https://www.geeksforgeeks.org/naive-bayes-classifiers/ <br>\n",
    "[15] https://towardsdatascience.com/naive-bayes-classifier-81d512f50a7c<br>\n",
    "[16] https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761<br>\n",
    "[17] https://www.sciencedirect.com/topics/immunology-and-microbiology/support-vector-machine<br>\n",
    "[18] https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47 <br>\n",
    "[19] https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html#:~:text=This%20example%20illustrates%20the%20effect,high%20values%20meaning%20'close'.  <br>\n",
    "[20] https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html <br>\n",
    "[21] https://www.datacamp.com/tutorial/svm-classification-scikit-learn-python#rdl <br>\n",
    "[22] https://scikit-learn.org/stable/modules/cross_validation.html<br>\n",
    "[23] https://towardsdatascience.com/machine-learning-project-17-compare-classification-algorithms-87cb50e1cb60<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
